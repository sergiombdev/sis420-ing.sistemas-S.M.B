{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "# https://github.com/sergiombdev/sis420-ing.sistemas-S.M.B/tree/master/laboratorios/laboratorio12\n",
        "\n",
        "# Alumno: Mendoza Benito Sergio\n",
        "# Carrera: Ingenieria de Sistemas\n",
        "# Grupo laboratorio: 12\n",
        "# Materia: sis420\n",
        "\n",
        "\n",
        "# opte por usar clasificacion multiclase con Cross Entropy\n",
        "\n",
        "# tuve que agrgrear el dataset ex3data1.mat\n",
        "\n",
        "# modifique las caracteristicas de entrada que en este son 400 , cree 300 capas ocultas y son 10 resultados posibles del 0 al 9\n",
        "# MLPClassification(D_in=400, H=300, D_out=10)\n",
        "\n",
        "\n",
        "# cree la sgt funcion :\n",
        "\n",
        "# def prediccionHandler(data):\n",
        "#     listMayor = []\n",
        "#     for value in data:\n",
        "#         mayor = 0\n",
        "\n",
        "#         for index in range( len(value) ):\n",
        "#             if( value[index] >= value[mayor]):\n",
        "#                 mayor = index\n",
        "#         listMayor.append(mayor)\n",
        "    \n",
        "#     return listMayor\n",
        "\n",
        "# que se encarga de obtener el mayor valor obtenido para comprar con la y al momento de predecir el resultado\n",
        "\n",
        "# el resultado del entrenamiento es de 93%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSnRB_eoC_l6"
      },
      "source": [
        "# El Perceptrón Multicapa - Clasificación"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DtxDBiy1C_l7"
      },
      "source": [
        "## El Perceptrón Multicapa"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-TWxM-E7C_l8"
      },
      "source": [
        "En el [post](https://sensioai.com/blog/023_mlp_backprop) anterior hemos introducido el modelo de `Perceptrón Multicapa`, o MLP, la arquitectura de red neuronal más básica basada en el [Perceptrón](https://sensioai.com/blog/012_perceptron1). Hemos visto cómo calcular la salida de un MLP de dos capas a partir de unas entradas y cómo encontrar los pesos óptimos para una tarea de regresión. En este post vamos a mejorar la implementación de nuestro MLP de dos capas para que sea capaz también de llevar a cabo tareas de clasificación.\n",
        "\n",
        "![](https://www.researchgate.net/profile/Mohamed_Zahran6/publication/303875065/figure/fig4/AS:371118507610123@1465492955561/A-hypothetical-example-of-Multilayer-Perceptron-Network.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2V08XKGsC_l8"
      },
      "source": [
        "## Implementación"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3YcI_SDC_l9"
      },
      "source": [
        "La mayoría del código que utilizaremos fue desarrollado para el `Perceptrón` y lo puedes encontrar en este [post](https://sensioai.com/blog/018_perceptron_final). Lo único que cambiaremos es la lógica del modelo, el resto de funcionalidad (funciones de pérdida, funciones de activación, etc, siguen siendo exactamente igual)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJgdiC8JC_l9"
      },
      "source": [
        "### Funciones de activación"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRB3jc3vC_l-"
      },
      "source": [
        "Para la capa oculta de nuestro MLP utilizaremos una función de activación de tipo `relu`, de la cual necesitaremos su derivada."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-05T16:49:53.041393Z",
          "start_time": "2020-08-05T16:49:53.024396Z"
        },
        "id": "wgVcl-XSC_l-"
      },
      "outputs": [],
      "source": [
        "def relu(x):\n",
        "  return np.maximum(0, x)\n",
        "\n",
        "def reluPrime(x):\n",
        "  return x > 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dU7d0eoC_mA"
      },
      "source": [
        "En cuanto a las funciones de activación que utilizaremos a la salida del MLP, éstas son las que hemos introducido en posts anteriores:\n",
        "\n",
        "- Lineal: usada para regresión (junto a la función de pérdida MSE).\n",
        "- Sigmoid: usada para clasificación binaria (junto a la función de pérdida BCE).\n",
        "- Softmax: usada para clasificación multiclase (junto a la función de pérdida crossentropy, CE)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-05T16:49:53.311543Z",
          "start_time": "2020-08-05T16:49:53.298548Z"
        },
        "id": "GkAM7SNnC_mA"
      },
      "outputs": [],
      "source": [
        "def linear(x):\n",
        "    return x\n",
        "\n",
        "def sigmoid(x):\n",
        "  return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def softmax(x):\n",
        "    return np.exp(x) / np.exp(x).sum(axis=-1,keepdims=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-sEKB6OC_mB"
      },
      "source": [
        "### Funciones de pérdida"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vonDh_1C_mB"
      },
      "source": [
        "Como acabamos de comentar en la sección anterior, estas son las funciones de pérdida que hemos visto hasta ahora para las diferentes tareas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-05T16:49:53.677416Z",
          "start_time": "2020-08-05T16:49:53.673343Z"
        },
        "id": "Kj5eX-RGC_mC"
      },
      "outputs": [],
      "source": [
        "# Mean Square Error -> usada para regresión (con activación lineal)\n",
        "def mse(y, y_hat):\n",
        "    return np.mean((y_hat - y.reshape(y_hat.shape))**2)\n",
        "\n",
        "# Binary Cross Entropy -> usada para clasificación binaria (con sigmoid)\n",
        "def bce(y, y_hat):\n",
        "    return - np.mean(y.reshape(y_hat.shape)*np.log(y_hat) - (1 - y.reshape(y_hat.shape))*np.log(1 - y_hat))\n",
        "\n",
        "# Cross Entropy (aplica softmax + cross entropy de manera estable) -> usada para clasificación multiclase\n",
        "def crossentropy(y, y_hat):\n",
        "    logits = y_hat[np.arange(len(y_hat)),y]\n",
        "    entropy = - logits + np.log(np.sum(np.exp(y_hat),axis=-1))\n",
        "    return entropy.mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xg-RTxdmC_mD"
      },
      "source": [
        "Y sus derivadas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-05T16:49:53.945375Z",
          "start_time": "2020-08-05T16:49:53.925371Z"
        },
        "id": "ysl9IEbJC_mD"
      },
      "outputs": [],
      "source": [
        "def grad_mse(y, y_hat):\n",
        "    return y_hat - y.reshape(y_hat.shape)\n",
        "\n",
        "def grad_bce(y, y_hat):\n",
        "    return y_hat - y.reshape(y_hat.shape)\n",
        "\n",
        "def grad_crossentropy(y, y_hat):\n",
        "    answers = np.zeros_like(y_hat)\n",
        "    answers[np.arange(len(y_hat)),y] = 1    \n",
        "    return (- answers + softmax(y_hat)) / y_hat.shape[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8REuRF9C_mE"
      },
      "source": [
        "### Implementación MLP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F43Th_WUC_mE"
      },
      "source": [
        "Ahora que ya tenemos definidas las diferentes funciones de activación y de pérdida que necesitamos, vamos a implementar nuestro MLP de dos capas capaz de llevar a cabo tanto tareas de regresión como de clasificación. Del mismo modo que ya hicimos con el `Perceptrón`, definiremos una clase base que servirá para la implementación de las clases particulares para cada caso."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-05T16:49:54.342062Z",
          "start_time": "2020-08-05T16:49:54.325063Z"
        },
        "code_folding": [
          3,
          14,
          20,
          55
        ],
        "id": "RHcMxaeeC_mE"
      },
      "outputs": [],
      "source": [
        "# clase base MLP \n",
        "\n",
        "class MLP():\n",
        "  def __init__(self, D_in, H, D_out, loss, grad_loss, activation):\n",
        "    # pesos de la capa 1\n",
        "    self.w1, self.b1 = np.random.normal(loc=0.0,\n",
        "                                  scale=np.sqrt(2/(D_in+H)),\n",
        "                                  size=(D_in, H)), np.zeros(H)\n",
        "    # pesos de la capa 2\n",
        "    self.w2, self.b2 = np.random.normal(loc=0.0,\n",
        "                                  scale=np.sqrt(2/(H+D_out)),\n",
        "                                  size=(H, D_out)), np.zeros(D_out)\n",
        "    self.ws = []\n",
        "    # función de pérdida y derivada\n",
        "    self.loss = loss\n",
        "    self.grad_loss = grad_loss\n",
        "    # función de activación\n",
        "    self.activation = activation\n",
        "\n",
        "  def __call__(self, x):\n",
        "    # salida de la capa 1\n",
        "    self.h_pre = np.dot(x, self.w1) + self.b1\n",
        "    self.h = relu(self.h_pre)\n",
        "    # salida del MLP\n",
        "    y_hat = np.dot(self.h, self.w2) + self.b2 \n",
        "    return self.activation(y_hat)\n",
        "    \n",
        "  def fit(self, X, Y, epochs = 100, lr = 0.001, batch_size=None, verbose=True, log_each=1):\n",
        "    batch_size = len(X) if batch_size == None else batch_size\n",
        "    batches = len(X) // batch_size\n",
        "    l = []\n",
        "    for e in range(1,epochs+1):     \n",
        "        # Mini-Batch Gradient Descent\n",
        "        _l = []\n",
        "        for b in range(batches):\n",
        "            # batch de datos\n",
        "            x = X[b*batch_size:(b+1)*batch_size]\n",
        "            y = Y[b*batch_size:(b+1)*batch_size] \n",
        "            # salida del perceptrón\n",
        "            y_pred = self(x) \n",
        "            # función de pérdida\n",
        "            loss = self.loss(y, y_pred)\n",
        "            _l.append(loss)        \n",
        "            # Backprop \n",
        "            dldy = self.grad_loss(y, y_pred) \n",
        "            grad_w2 = np.dot(self.h.T, dldy)\n",
        "            grad_b2 = dldy.mean(axis=0)\n",
        "            dldh = np.dot(dldy, self.w2.T)*reluPrime(self.h_pre)      \n",
        "            grad_w1 = np.dot(x.T, dldh)\n",
        "            grad_b1 = dldh.mean(axis=0)\n",
        "            # Update (GD)\n",
        "            self.w1 = self.w1 - lr * grad_w1\n",
        "            self.b1 = self.b1 - lr * grad_b1\n",
        "            self.w2 = self.w2 - lr * grad_w2\n",
        "            self.b2 = self.b2 - lr * grad_b2\n",
        "        l.append(np.mean(_l))\n",
        "        # guardamos pesos intermedios para visualización\n",
        "        self.ws.append((\n",
        "            self.w1.copy(),\n",
        "            self.b1.copy(),\n",
        "            self.w2.copy(),\n",
        "            self.b2.copy()\n",
        "        ))\n",
        "        if verbose and not e % log_each:\n",
        "            print(f'Epoch: {e}/{epochs}, Loss: {np.mean(l):.5f}')\n",
        "\n",
        "  def predict(self, ws, x):\n",
        "    w1, b1, w2, b2 = ws\n",
        "    h = relu(np.dot(x, w1) + b1)\n",
        "    y_hat = np.dot(h, w2) + b2\n",
        "    return self.activation(y_hat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-05T16:57:40.536617Z",
          "start_time": "2020-08-05T16:57:40.515590Z"
        },
        "id": "hi8j2S2mC_mF"
      },
      "outputs": [],
      "source": [
        "# MLP para regresión\n",
        "class MLPRegression(MLP):\n",
        "    def __init__(self, D_in, H, D_out):\n",
        "        super().__init__(D_in, H, D_out, mse, grad_mse, linear)\n",
        "\n",
        "# MLP para clasificación binaria\n",
        "class MLPBinaryClassification(MLP):\n",
        "    def __init__(self, D_in, H, D_out):\n",
        "        super().__init__(D_in, H, D_out, bce, grad_bce, sigmoid)\n",
        "\n",
        "# MLP para clasificación multiclase\n",
        "class MLPClassification(MLP):\n",
        "    def __init__(self, D_in, H, D_out):\n",
        "        super().__init__(D_in, H, D_out, crossentropy, grad_crossentropy, linear)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usjgueZ8C_mG"
      },
      "source": [
        "Vamos a probar ahora nuestra implementación para diferentes ejemplos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bs_PKS-QC_mG"
      },
      "source": [
        "## Regresión"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9B3WrUhC_mG"
      },
      "source": [
        "En primer lugar, vamos a replicar los resultados obtenidos en el post anterior para verificar que nuestro modelo de MLP sigue funcionando bien."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-05T16:50:02.227502Z",
          "start_time": "2020-08-05T16:50:02.114509Z"
        },
        "id": "vftgiuJtC_mH",
        "outputId": "75fab614-a6fc-4256-9859-3711644a44fc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "# modulo para cargar archivos en formato MATLAB\n",
        "from scipy.io import loadmat\n",
        "import os\n",
        "# Libreria para graficos\n",
        "from matplotlib import pyplot\n",
        "\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "def displayData(X, example_width=None, figsize=(10, 10)):\n",
        "    \"\"\"\n",
        "    Muestra datos 2D almacenados en X en una cuadrícula apropiada.\n",
        "    \"\"\"\n",
        "    # Calcula filas, columnas\n",
        "    if X.ndim == 2:\n",
        "        m, n = X.shape\n",
        "    elif X.ndim == 1:\n",
        "        n = X.size\n",
        "        m = 1\n",
        "        X = X[None]  # Promocionar a una matriz bidimensional\n",
        "    else:\n",
        "        raise IndexError('La entrada X debe ser 1 o 2 dimensinal.')\n",
        "\n",
        "    example_width = example_width or int(np.round(np.sqrt(n)))\n",
        "    example_height = n / example_width\n",
        "\n",
        "    # Calcula el numero de elementos a mostrar\n",
        "    display_rows = int(np.floor(np.sqrt(m)))\n",
        "    display_cols = int(np.ceil(m / display_rows))\n",
        "\n",
        "    fig, ax_array = pyplot.subplots(display_rows, display_cols, figsize=figsize)\n",
        "    fig.subplots_adjust(wspace=0.025, hspace=0.025)\n",
        "\n",
        "    ax_array = [ax_array] if m == 1 else ax_array.ravel()\n",
        "\n",
        "    for i, ax in enumerate(ax_array):\n",
        "        ax.imshow(X[i].reshape(example_width, example_width, order='F'),\n",
        "                  cmap='Greys', extent=[0, 1, 0, 1])\n",
        "        ax.axis('off')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OaOQvjq7C_mP"
      },
      "source": [
        "## Clasificación Multiclase"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-xGSLRnC_mP"
      },
      "source": [
        "Por último vamos a ver cómo aplicar nuestro modelo para clasificación en multiples clases."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-05T17:05:47.527647Z",
          "start_time": "2020-08-05T17:05:47.393648Z"
        },
        "id": "1JiU9ImNC_mQ",
        "outputId": "856829d4-3aae-4ac4-f929-a0ff353af129"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[45. 36. 43. ... 49. 49. 49.]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "#data = loadmat(os.path.join('ex3data1.mat'))\n",
        "data = np.loadtxt( os.path.join(\"processed_balanced_train.csv\"), skiprows=1, delimiter = ',')\n",
        "\n",
        "\n",
        "X, y = data[:120000,1:], data[:120000,0]\n",
        "# establecer el dígito cero en 0, en lugar del 10 asignado a este conjunto de datos\n",
        "# Esto se hace debido a que el conjunto de datos se utilizó en MATLAB donde no hay índice 0\n",
        "#y[y == 10] = 0\n",
        "m = y.size\n",
        "\n",
        "print(y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-05T17:08:01.961788Z",
          "start_time": "2020-08-05T17:08:01.891163Z"
        },
        "id": "q9e_HJQUC_mQ",
        "outputId": "1c6ddea6-2cfd-4163-ec59-adcf651c0df3"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn [52], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m model \u001b[39m=\u001b[39m MLPClassification(D_in\u001b[39m=\u001b[39m\u001b[39m784\u001b[39m, H\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, D_out\u001b[39m=\u001b[39m\u001b[39m52\u001b[39m)\n\u001b[0;32m      2\u001b[0m epochs, lr \u001b[39m=\u001b[39m \u001b[39m1000\u001b[39m, \u001b[39m0.5\u001b[39m\n\u001b[1;32m----> 3\u001b[0m model\u001b[39m.\u001b[39;49mfit(X, y\u001b[39m.\u001b[39;49mastype(\u001b[39mint\u001b[39;49m), epochs, lr, batch_size\u001b[39m=\u001b[39;49m\u001b[39m120000\u001b[39;49m, log_each\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m)\n",
            "Cell \u001b[1;32mIn [34], line 49\u001b[0m, in \u001b[0;36mMLP.fit\u001b[1;34m(self, X, Y, epochs, lr, batch_size, verbose, log_each)\u001b[0m\n\u001b[0;32m     47\u001b[0m grad_b2 \u001b[39m=\u001b[39m dldy\u001b[39m.\u001b[39mmean(axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m     48\u001b[0m dldh \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdot(dldy, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mw2\u001b[39m.\u001b[39mT)\u001b[39m*\u001b[39mreluPrime(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mh_pre)      \n\u001b[1;32m---> 49\u001b[0m grad_w1 \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mdot(x\u001b[39m.\u001b[39;49mT, dldh)\n\u001b[0;32m     50\u001b[0m grad_b1 \u001b[39m=\u001b[39m dldh\u001b[39m.\u001b[39mmean(axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m     51\u001b[0m \u001b[39m# Update (GD)\u001b[39;00m\n",
            "File \u001b[1;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "model = MLPClassification(D_in=784, H=10, D_out=52)\n",
        "epochs, lr = 1000, 0.5\n",
        "model.fit(X, y.astype(int), epochs, lr, batch_size=120000, log_each=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def prediccionHandler(data):\n",
        "    listMayor = []\n",
        "    for value in data:\n",
        "        mayor = 0\n",
        "\n",
        "        for index in range( len(value) ):\n",
        "            if( value[index] >= value[mayor]):\n",
        "                mayor = index\n",
        "        listMayor.append(mayor)\n",
        "    \n",
        "    return listMayor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exactitud de prediccion 96.0000%\n"
          ]
        }
      ],
      "source": [
        "XPrueba = X[120000:, :].copy()\n",
        "# print(y[3999:4999])\n",
        "prediccion = model.predict([model.w1, model.b1, model.w2, model.b2], XPrueba)\n",
        "# print(prediccion)\n",
        "# print(prediccionHandler(prediccion))\n",
        "print( 'Exactitud de prediccion {:.4f}%'.format(np.mean( prediccionHandler(prediccion) == y[120000:])* 100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9\n",
            "[[-4.28477499 -6.58473698 -2.40076691 -3.39756367  6.44575693  0.76387292\n",
            "  -3.31451605  3.59201938  0.6633309  11.08549767]]\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x1000 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "XPrueba = X[4899:4900, :].copy()\n",
        "print(y[4900])\n",
        "prediccion = model.predict([model.w1, model.b1, model.w2, model.b2], XPrueba)\n",
        "print(prediccion)\n",
        "displayData(XPrueba)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "233.594px"
      },
      "toc_section_display": true,
      "toc_window_display": false
    },
    "vscode": {
      "interpreter": {
        "hash": "5f1de7d2f8b2ea13c275b55a1a168baa6b4c6d64260a02c6ee9ee64f3ff538fa"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
